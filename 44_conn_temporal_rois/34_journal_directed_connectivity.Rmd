---
title: 'Directed Connectivity: R4'
author: "Zarrar Shehzad"
date: "May 9, 2015"
output:
  html_document:
    number_sections: yes
    toc: yes
---

```{r packages}
library(plyr)
library(corrplot)
library(RColorBrewer)
library(knitr)
library(ggplot2)
library(igraph)

library(doMC)
registerDoMC(10)
```

# Setup

We start by setting some variables.

```{r, echo=FALSE}
#base <- "~/Dropbox/Research/facemem/connpaper"
base <- "/data/psych/faceMemoryMRI/scripts/connpaper"
```

```{r setup, results='hold'}
setwd(base)

# Make sure to not have any progress when building
prog <- "none"
#prog <- "text"

# We want to select a subset of the extract ROIs for our analyses
subjects <- as.character(as.matrix(read.table("sublist_all.txt")))
runtypes <- c("Questions", "NoQuestions")
conds    <- c("bio", "phys")
# We want to select a subset of the extract ROIs for our analyses
snames <- c("R IOG", "R mFus", "R aFus", "R vATL", 
             "L IOG", "L mFus", "L aFus", "L vATL")

nrois <- length(snames)
```

And then we load the data.

```{r load, results='hold'}
setwd(base)

# Load all the time-series
cat("time-series\n")
load("data/ts_rois_ofa+ffa+vatl.rda")
head(dat$Questions$bio$tb9226)

# Get the scaled time-series
cat("scaled time-series\n")
scale.dat <- llply(dat, function(rtdat) {
  llply(rtdat, function(cdat) {
    llply(cdat, function(sdat) {
      scale(sdat)
    })
  })
})
head(scale.dat$Questions$bio$tb9226)

# Get the correlations (r values)
# 2 x 2 x 16 x 6 x 6
# runtypes x conditions x subjects x rois x rois
cat("correlations\n")
rmats <- laply(runtypes, function(runtype) {
  cat("Runtype:", runtype, "\n")
  laply(conds, function(cond) {
    cat("- Condition:", cond, "\n")
    laply(subjects, function(subject) {
      # Compute correlation between ROI time-series
      ts.mat    <- dat[[runtype]][[cond]][[subject]]
      r.mat     <- cor(ts.mat)
      return(r.mat)
    }, .progress=prog)
  })
})
dimnames(rmats) <- list(runtype=runtypes, condition=conds, subject=subjects, 
                        roi=snames, roi=snames)
```

# Undirected Connections

We now want to determine the connections that exist between pairs of regions. In
particular, we want to only keep direct connections between two areas. We do this 
via two approaches:

  1. A-priori hypotheses. We will exclude all heterotopic connections.
  2. Data-driven. We will remove any connections that are conditionally independent.

## What connections to keep/remove a-priori?

### Exclude heterotopic connections

Note that here we can't force the direction of the connections.

  * 0 = no connection
  * 1 = yes connection

```{r gaps-hetero}
nrois <- length(snames)
lh.inds <- 1:(nrois/2)
rh.inds <- (nrois/2+1):nrois
# 0 = no connection; 1 = yes connection
fixed.conn.mat <- matrix(0, nrois, nrois, dimnames=list(roi=snames, roi=snames))
# these are the right-hemisphere only connections
fixed.conn.mat[lh.inds,lh.inds] <- 1
# now the left-hemisphere connections
fixed.conn.mat[rh.inds,rh.inds] <- 1
# keep the diagonals out of this
diag(fixed.conn.mat) <- 0

print(fixed.conn.mat)
```

### Keep homotopic connections

Let's add back the homotopic connections.

```{r gaps-homo}
diag(fixed.conn.mat[lh.inds,rh.inds]) <- 1
diag(fixed.conn.mat[rh.inds,lh.inds]) <- 1

print(fixed.conn.mat)
```

### Result

Let's visualize this simple network for our viewers:

```{r gaps-viz}
# TODO
```

## What connections to keep/remove based on data?

### Concatenate subject data

For this we first concatenate the time-series across all the subjects. This way
we can get the conditional independence between pairs of regions from all 
subjects at once.

```{r concat}
# Compile all subjects time-series for each condition and each runtype
concat.scale.dat <- llply(runtypes, function(runtype) {
  cat("Runtype:", runtype, "\n")
  ret <- llply(conds, function(cond) {
    cat("- condition:", cond, "\n")
    #do.call("rbind", scale.dat[[runtype]][[cond]])
    ret <- ldply(subjects, function(subject) {
      scale.dat[[runtype]][[cond]][[subject]]
    }, .parallel=F)
    as.matrix(ret)
  })
  ## we also com
  names(ret) <- conds
  ret
})
names(concat.scale.dat) <- runtypes

# Now collapse across runtype and condition
Z <- rbind(
  concat.scale.dat$Questions$bio, concat.scale.dat$Questions$phys, 
  concat.scale.dat$NoQuestions$bio, concat.scale.dat$NoQuestions$phys
)
```

### Exclude conditionally independent connections

Note that none of the connections were conditionally independent! So all is the
same. We use the pcalg package with the skeleton function and the first two 
steps in the Peter Clark (PC) algorithm.

```{r ci-calc}
setwd(base)
source("44_conn_temporal_rois/undirected_functions/alg_pc.R")

pMat  <- conn_pc_pvals(Z, fixedGaps=fixed.conn.mat==1)
aMat  <- (pMat < 0.05)*1 * fixed.conn.mat
diag(aMat) <- 0
dimnames(aMat) <- list(roi=snames, roi=snames)

print(aMat) # note this procedure didn't actually remove anything though
```

### Results

Let's visualize it again.

```{r ci-viz}
# TODO
```

# Directed UnWeighted Connectivity

Let's get the overall direction of the connections. We use only the Questions run concatenated data here (or we could run for each condition).

First we load the relevant functions. We will be using 5 different methods and taking the consensus direction across those methods for each connection. These approaches were highly ranked in the Ramsey paper. 

```{r udconn-funs}
setwd(base)
source("44_conn_temporal_rois/directed_functions/lofs.R")
source("44_conn_temporal_rois/directed_functions/pwling.R")
source("44_conn_temporal_rois/directed_functions/patel.R")

conn_skew <- function(gadj, sdat, rmat) {
 # yes skewness correction
 res <- pwling(t(sdat), 3, S=t(gadj), to.scale=F, C=rmat, verbose=F)
 t(res$dag) # to go from i->j to j->i
}

conn_rskew <- function(gadj, sdat, rmat) {
 # yes skewness correction
 res <- pwling(t(sdat), 4, S=t(gadj), to.scale=F, C=rmat, verbose=F)
 t(res$dag) # to go from i->j to j->i
}

conn_R3 <- function(gadj, sdat, rmat=NULL) {
 dag <- lofs.r3(gadj, sdat, to.scale=F)
 dag
}

conn_R4 <- function(gadj, sdat, rmat) {
 res   <- lofs.r4(gadj, sdat, cordat=rmat, to.scale=F, verbose=F, parallel=T)
 res$dag
}

conn_patel <- function(gadj, dat, rmat=NULL) {
  res   <- patel.tau(dat, gadj, to.scale=F, verbose=F)
  res$dag
}
```

Let's do the calculations!

```{r}
#Z <- rbind(concat.scale.dat$Questions$bio, concat.scale.dat$Questions$phys)
rmat.bio <- cor(concat.scale.dat$Questions$bio)
rmat.phys<- cor(concat.scale.dat$Questions$phys)

# Skew
skews <- list(
  bio=conn_skew(aMat, concat.scale.dat$Questions$bio, rmat.bio), 
  phys=conn_skew(aMat, concat.scale.dat$Questions$phys, rmat.phys)
)

# RSkew
rskews <- list(
  bio=conn_rskew(aMat, concat.scale.dat$Questions$bio, rmat.bio), 
  phys=conn_rskew(aMat, concat.scale.dat$Questions$phys, rmat.phys)
)

# R3
r3s <- list(
  bio=conn_R3(aMat, concat.scale.dat$Questions$bio, rmat.bio), 
  phys=conn_R3(aMat, concat.scale.dat$Questions$phys, rmat.phys)
)

# R4
r4s <- list(
  bio=conn_R4(aMat, concat.scale.dat$Questions$bio, rmat.bio), 
  phys=conn_R4(aMat, concat.scale.dat$Questions$phys, rmat.phys)
)

# Patel's Tau on concatenated data
pats <- list(
  bio=conn_patel(aMat, concat.scale.dat$Questions$bio, rmat.bio), 
  phys=conn_patel(aMat, concat.scale.dat$Questions$phys, rmat.phys)
)

# Get the consensus
consensus.wt <- list(
  bio = skews$bio + rskews$bio + r3s$bio + r4s$bio + pats$bio, 
  phys = skews$phys + rskews$phys + r3s$phys + r4s$phys + pats$phys
)
consensus <- list(
  bio = ((skews$bio + rskews$bio + r3s$bio + r4s$bio + pats$bio)>=3)*1, 
  phys = ((skews$phys + rskews$phys + r3s$phys + r4s$phys + pats$phys)>=3)*1
)
```

```{r udconn-plot}
setwd(base)
# Get the coordinates for the 6 ROIs
coords <- as.matrix(read.table("44_conn_temporal_rois/z_coords.txt"))
dimnames(coords) <- list(roi=snames, dim=c("x","y","z"))

cols2 <- brewer.pal(8, "Dark2")[c(1,3,4)] # Questions, NoQuestions, and Overlap
cols <- brewer.pal(3, "Set1") # Condition colors

ri <- 1
ci <- 2
#for (ri in 1:2) {
  for (ci in 1:2) {
    old.mar <- par()$mar
    #par(mar=c(0,0,2,0))
    
    mat  <- consensus[[ci]]
    g    <- graph.adjacency(mat, mode="directed", weighted=T, diag=F)
    
    # Want extra curves for 1-3 or 4-6 (vATL <-> FFA)
    curves <- apply(get.edges(g, E(g)), 1, function(x) {
      if (all(x %in% c(1,3)) || all(x %in% c(4,6))) {
        return(0.6)
      } else {
        return(0.25)
      }
    })
    
    plot.igraph(g, 
                edge.width=E(g)$weight*2.5, 
                edge.curved=curves, 
                #edge.color=cols[ci], 
                vertex.size=40,
                vertex.color=cols2[ri], #"red",
                vertex.frame.color="white", 
                vertex.label.color = "white",
                vertex.label.family = "sans", 
                vertex.label.font = 2, 
                vertex.label.cex = 1, 
                #vertex.label.size = 20, 
                layout=coords)#, 
                #main=sprintf("%s : %s", runtypes[ri], conds[ci]))
    par(mar=old.mar)
  }
#}
```

# Directed Weighted Connectivity

## Subject-Level Directed Connectivity

We calculate the directed connectivity weights with the R4 method for each 
subject.

```{r dconn-subj}
setwd(base)
source("44_conn_temporal_rois/directed_functions/lofs.R")

conn_R4_raw <- function(gadj, sdat, rmat, ...) {
  res   <- lofs.r4(gadj, sdat, cordat=rmat, to.scale=F, parallel=T, ...)
  res$W
}

dir.mats <- laply(1:length(runtypes), function(ri) {
  cat("Runtype:", runtypes[ri], "\n")
  laply(1:length(conds), function(ci) {
    cat("- condition:", conds[ci], "\n")
    laply(1:length(subjects), function(si) {
      #cat("  ...subject:", subjects[si], "\n")
      sts  <- scale.dat[[ri]][[ci]][[si]] # scaled time-series
      rmat <- rmats[ri,ci,si,,]           # correlation matrix
      conn_R4_raw(aMat, sts, rmat, zeta=4)# calc directed connectivity with R4
      # note that the zeta here is the range +/- of the 'beta' values to search
      # during the fitting process
    }, .progress=prog, .parallel=F)
  })
})
dimnames(dir.mats) <- list(runtype=runtypes, condition=conds, subject=subjects, 
                           target=snames, seed=snames)
```

### Significance Estimates - Bio vs Phys Differences

The main point of doing the subject-level estimates was for any easy approach to 
estimate the significance.

#### Questions

```{r dconn-sig-q, results='hold'}
# T-Statistic
tres <- apply(dir.mats[1,,,,], c(3,4), function(x) {
  if (all(x==1) || all(x==0)) {
    return(0)
  } else {
    return(t.test(x[1,], x[2,], paired=T)$statistic)
  }
})
colnames(tres) <- snames
rownames(tres) <- snames

# P-value for Tstat
pres <- apply(dir.mats[1,,,,], c(3,4), function(x) {
  if (all(x==1) || all(x==0)) {
    return(0)
  } else {
    return(t.test(x[1,], x[2,], paired=T)$p.value)
  }
})
colnames(pres) <- snames
rownames(pres) <- snames

# P-value with wilcox signed rank test
pres2 <- apply(dir.mats[1,,,,], c(3,4), function(x) {
  if (all(x==1) || all(x==0)) {
    return(0)
  } else {
    return(wilcox.test(x[1,], x[2,], paired=T)$p.value)
  }
})
colnames(pres2) <- snames
rownames(pres2) <- snames

cat("Tstat\n")
round(tres, 3)
cat("P-val for Tstat\n")
round(pres, 2)
cat("Pval with wilcox test\n")
round(pres2, 2)
```

We can see here that our results show the following significant (p < 0.05) 
connections:

  * L vATL => L FFA : p = 0.02, t = 2.6, bio > phys
  * L OFA => L FFA : p = 0.04, t = -1.1, phys > bio

And we have the almost significant (p < 0.1) connections:

  * L FFA => R FFA : p = 0.09, t = -2.1, phys > bio

And the almost almost significant connections (p < 0.15)

  * R FFA => R FFA : p = 0.13, t = -1.5, phys > bio

#### No Questions

```{r dconn-sig-nq, results='hold'}
# T-Statistic
tres <- apply(dir.mats[2,,,,], c(3,4), function(x) {
  if (all(x==1) || all(x==0)) {
    return(0)
  } else {
    return(t.test(x[1,], x[2,], paired=T)$statistic)
  }
})
colnames(tres) <- snames
rownames(tres) <- snames

# P-value for Tstat
pres <- apply(dir.mats[2,,,,], c(3,4), function(x) {
  if (all(x==1) || all(x==0)) {
    return(0)
  } else {
    return(t.test(x[1,], x[2,], paired=T)$p.value)
  }
})
colnames(pres) <- snames
rownames(pres) <- snames

# P-value with wilcox signed rank test
pres2 <- apply(dir.mats[2,,,,], c(3,4), function(x) {
  if (all(x==1) || all(x==0)) {
    return(0)
  } else {
    return(wilcox.test(x[1,], x[2,], paired=T)$p.value)
  }
})
colnames(pres2) <- snames
rownames(pres2) <- snames

cat("Tstat\n")
round(tres, 3)
cat("P-val for Tstat\n")
round(pres, 2)
cat("Pval with wilcox test\n")
round(pres2, 2)
```

Oh crap, the connection of interest replicates with the NoQuestions run. Oh wait
it is actually in totally the reverse direction!!!

For the significant connections (p < .05), we have:

  * L vATL => L FFA : p = 0.02, t = -2.4, phys > bio

For the almost significant connections (p < 0.1), we have:

  * R OFA => R vATL : p = 0.09, t = 1.8, bio > phys

For the almost almost significant connection (p < 0.16), we have:

  * R FFA => R OFA : p = 0.12, t = -1.7, phys > bio
  * R vATL => R OFA : p = 0.13, t = -1.3, phys > bio
  * R vATL => R FFA : p = 0.16, t = -1.7, phys > bio
  * R vATL => L vATL : p = 0.14, t = -2.0, phys > bio


## Group-Level Connectivity

### Calculate Average Values

We can get the average of each subject's directed connections. For now, I'll 
take this approach.

```{r grp-ave}
# Just get the average instead for each condition/runtype
ave.dconn <- apply(dir.mats, c(1,2,4,5), mean)

# Average of the paired differene
diff.dconn <- apply(dir.mats, c(1,4,5), function(x) mean(x[1,]-x[2,]))

# Compute the p-values for bio/phys for q/noq
pval.dconn0 <- apply(dir.mats, c(1,2,4,5), function(x) {
  if (all(x==1) || all(x==0)) {
    return(0)
  } else {
    return(t.test(x)$p.value)
  }
})

# Recompute the p-values for the differences bio vs phys
pval.dconn <- laply(1:2, function(ri) {
  apply(dir.mats[ri,,,,], c(3,4), function(x) {
    if (all(x==1) || all(x==0)) {
      return(1)
    } else {
      return(t.test(x[1,], x[2,], paired=T)$p.value)
    }
  })  
})
dimnames(pval.dconn) <- list(runtype=runtypes, target=snames, seed=snames)
```

### Visualize

We can visualize the connections now in three ways. First as plain tables, second as corrplots and third
as networks.

#### Tables

```{r grp-viz-tables, results='hold'}
odir <- file.path(base, "tables/table_dir_conn")
if (!file.exists(odir)) dir.create(odir)
for (ri in 1:2) {
  # bio, phys
  for (ci in 1:2) {
    #cat(sprintf("%s - %s\n", runtypes[ri], conds[ci]))
    tmp <- ave.dconn[ri,ci,,]
    round(tmp, 3)
    write.table(tmp, file=file.path(odir, sprintf("ave_dconn_%s_%s.tab", runtypes[ri], conds[ci])))
    ptmp <- pval.dconn0[ri,ci,,]
    write.table(ptmp, file=file.path(odir, sprintf("sig_ave_dconn_%s_%s.tab", runtypes[ri], conds[ci])))
  }
  # difference
  tmp <- diff.dconn[ri,,]
  round(tmp, 3)
  write.table(tmp, file=file.path(odir, sprintf("diff_dconn_%s.tab", runtypes[ri])))
  ptmp <- pval.dconn[ri,,]
  write.table(ptmp, file=file.path(odir, sprintf("sig_diff_dconn_%s.tab", runtypes[ri])))
}
```

#### Correlation Plots

Xs here mean that connection wasn't significantly different 

```{r grp-viz-corrplot, results='hold'}
for (ri in 1:2) {
  for (ci in 1:2) {
    #cat(sprintf("%s - %s\n", runtypes[ri], conds[ci]))
    tmp <- ave.dconn[ri,ci,,]
    ptmp <- pval.dconn[ri,,]
    cols <- rev(colorRampPalette(brewer.pal(10, "RdBu"))(20))
#     corrplot.mixed(tmp, lower="circle", upper="circle", diag='n', 
#                    outline=T, col=cols, tl.pos="lt", is.corr=F, # cl.lim=c(0,1), 
#                    cl.length=length(cols)/2+1, addgrid.col="grey", 
#                    title=sprintf("\n%s - %s\n", runtypes[ri], conds[ci]), 
#                    p.mat=ptmp, sig.level=0.1, mar=c(0,0,2,0))
      # TODO: add a number one on top of this!
      # also thinking of using a simpler black to white type of shading.
      corrplot(tmp, method="shade", diag=F, 
               outline=T, col=cols, tl.pos="lt", is.corr=F, # cl.lim=c(0,1), 
               cl.length=length(cols)/2+1, addgrid.col="grey", 
               title=sprintf("\n%s - %s\n", runtypes[ri], conds[ci]), 
               p.mat=(tmp==0)*1, sig.level=0.5, insig='blank', mar=c(0,0,2,0))
    corrRect(c(4,4), col="green", lwd=2)
  }
}
```

#### Network Graphs

Let's read in the coordinates of the ROIs to use for vertex placement in plots.

```{r grp-viz-coords, results='hold'}
setwd(base)
# Get the coordinates for the 6 ROIs
coords <- as.matrix(read.table("44_conn_temporal_rois/z_coords.txt"))
dimnames(coords) <- list(roi=snames, dim=c("x","y","z"))
## spit out
cat("coordinates\n")
print(coords)
```

Now we graph each combo of runtypes and conditions. Some notes:

  * Vertex color represents the runtype
    * Greenish = Quest
    * Pinkish = NoQuest
  * Line type represents the type of connection
    * Solid = Feedforward
    * Dashed = Feedback
    * Dotted = Lateral

```{r grp-viz1, results='hold'}
cols2 <- brewer.pal(8, "Dark2")[c(1,3,4)] # Questions, NoQuestions, and Overlap
cols <- brewer.pal(3, "Set1") # Condition colors

for (ri in 1:2) {
  for (ci in 1:2) {
    old.mar <- par()$mar
    par(mar=c(0,0,2,0))
  
    pmat <- t(pval.dconn0[ri,ci,,])
    mat  <- t(ave.dconn[ri,ci,,])
    mat  <- mat * (pmat<0.1)   # threshold matrix with p < 0.1
    g    <- graph.adjacency(mat, mode="directed", weighted=T, diag=F)
    
    # Want extra curves for 1-3 or 4-6 (vATL <-> FFA)
    curves <- apply(get.edges(g, E(g)), 1, function(x) {
      if (all(x %in% c(1,3)) || all(x %in% c(4,6))) {
        return(1)
      } else {
        return(0.4)
      }
    })
    # Want to have dotted lines for feedback
    linetypes <- apply(get.edges(g, E(g)), 1, function(x) {
      # feedback / feedforward
      if (all(x %in% 1:3) || all(x %in% 4:6)) {
        if (x[1] > x[2]) return(2)
        else return(1)
      } else { # homotopic
        return(3)
      }
    })
    
    plot.igraph(g, 
                edge.width=E(g)$weight*2.5, 
                edge.label=round(E(g)$weight, 2), 
                edge.lty=linetypes, 
                edge.curved=curves, 
                #edge.color=cols[ci], 
                vertex.size=40,
                vertex.color=cols2[ri], #"red",
                vertex.frame.color="white", 
                vertex.label.color = "white",
                vertex.label.family = "sans",
                layout=coords, 
                main=sprintf("%s : %s", runtypes[ri], conds[ci]))
    par(mar=old.mar)
  }
}
```

This shows the significant differences in the bio vs phys directed connectivity.
Positive values indicate 'bio > phys' while negative values indicate 
'phys > bio'.

So here we add the following note:

  * Edge color represents the condition that has larger directed connectivity
    * Red = Bio > Phys
    * Blue = Phys > Bio

```{r grp-viz2, results='hold'}
old.mar <- par()$mar
par(mar=c(0,0,2,0))

for (ri in 1:2) {
  pmat <- t(pval.dconn[ri,,])
  mat  <- t(diff.dconn[ri,,])
  mat  <- mat * (pmat<0.1)   # threshold matrix with p < 0.1
  g    <- graph.adjacency(mat, mode="directed", weighted=T, diag=F)
  
  # Want extra curves for 1-3 or 4-6 (vATL <-> FFA)
  curves <- apply(get.edges(g, E(g)), 1, function(x) {
    if (all(x %in% c(1,3)) || all(x %in% c(4,6))) {
      return(1)
    } else {
      return(0.4)
    }
  })
  # Want to have dotted lines for feedback
  linetypes <- apply(get.edges(g, E(g)), 1, function(x) {
    # feedback / feedforward
    if (all(x %in% 1:3) || all(x %in% 4:6)) {
      if (x[1] > x[2]) return(2)
      else return(1)
    } else { # homotopic
      return(3)
    }
  })
  # Edge color
  ecolors <- cols[(E(g)$weight < 0)*1 + 1]
  
  plot.igraph(g, 
              edge.width=E(g)$weight*2.5, 
              edge.label=round(E(g)$weight, 2), 
              edge.lty=linetypes, 
              edge.curved=curves, 
              edge.color=ecolors, 
              vertex.size=42,
              vertex.color=cols2[ri], #"red",
              vertex.frame.color= "white",
              vertex.label.color = "white",
              vertex.label.family = "sans",
              layout=coords, 
              main=sprintf("%s : bio vs phys", runtypes[ri]))
}

par(mar=old.mar)
```



```{r}
#old.mar <- par()$mar
#par(mar=c(0,0,2,0))
#for (ri in 1:2) {
ri<-1
  pmat <- t(pval.dconn[ri,,])
  mat  <- t(diff.dconn[ri,,])
  mat  <- mat * (pmat<0.05)   # threshold matrix with p < 0.1
  g    <- graph.adjacency(mat, mode="directed", weighted=T, diag=F)
  
  # Want extra curves for 1-3 or 4-6 (vATL <-> FFA)
  curves <- apply(get.edges(g, E(g)), 1, function(x) {
    if (all(x %in% c(1,4)) || all(x %in% c(4,6)) || all(x %in% c(8,6))) {
      return(.8)
    } else {
      return(0.2)
    }
  })
  # Edge color
  ecolors <- cols[(E(g)$weight < 0)*1 + 1]
  
  plot.igraph(g, 
              edge.width=E(g)$weight*4, 
              #edge.label=round(E(g)$weight, 2), 
              #edge.lty=linetypes, 
              edge.curved=curves, 
              edge.color=ecolors, 
              vertex.size=42,
              vertex.color=cols2[ri], #"red",
              vertex.frame.color= "white",
              vertex.label.color = "white",
              vertex.label.family = "sans",
              vertex.label.font = 2, 
              vertex.label.cex = 1.2, 
              layout=coords)#, 
              #main=sprintf("%s : bio vs phys", runtypes[ri]))
#par(mar=old.mar)

```
